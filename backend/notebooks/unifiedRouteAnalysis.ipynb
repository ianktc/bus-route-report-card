{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, date, time \n",
    "from pathlib import Path\n",
    "from scipy.spatial import KDTree\n",
    "from geopy.distance import geodesic\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "backend_dir = Path('.').resolve()\n",
    "input = Path(backend_dir,'data_in')\n",
    "output = Path(backend_dir, 'data_out')\n",
    "data_set = 'mdb-2253'\n",
    "target_route = '510'\n",
    "n_stops = 7\n",
    "\n",
    "# TTC Occupancy Enums\n",
    "# EMPTY (0), FEW SEATS AVAILABLE (2), FULL (5)\n",
    "\n",
    "# WEEKDAY M-F\n",
    "WEEKDAY_PEAK = 3.5 # 7AM - 10AM and 4PM - 7PM\n",
    "WEEKDAY_SHOULDER = 1 # 10AM - 4PM\n",
    "WEEKDAY_OFF_PEAK = 1 # 7PM - 7AM\n",
    "\n",
    "# WEEKEND S-S\n",
    "WEEKEND_PEAK = 1.5 # 10AM - 4PM\n",
    "WEEKEND_OFF_PEAK = 1 # 4PM - 10AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_out():\n",
    "    for file_path in output.iterdir():\n",
    "        if file_path.is_file():  \n",
    "            file_path.unlink() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_time(time_str):\n",
    "    try:\n",
    "        # Split time into components\n",
    "        h, m, s = map(int, time_str.split(\":\"))\n",
    "        # Normalize hours to wrap around at 24\n",
    "        h %= 24\n",
    "        # Return normalized time as a string\n",
    "        return f\"{h:02}:{m:02}:{s:02}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid time format: {time_str}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_feed_and_filter_by_route(feed, target_route_id):\n",
    "  matching_entities = []\n",
    "  for entity in feed.entity:\n",
    "      if entity.HasField('vehicle'):\n",
    "        vehicle = entity.vehicle\n",
    "        if vehicle.trip.route_id == str(target_route_id):\n",
    "            # print(\"occupancy is \", str(vehicle.occupancy_status))\n",
    "            matching_entities.append({\n",
    "                'id': entity.id,\n",
    "                'trip_id': vehicle.trip.trip_id,\n",
    "                'route_id': vehicle.trip.route_id,\n",
    "                'latitude': vehicle.position.latitude,\n",
    "                'longitude': vehicle.position.longitude,\n",
    "                'occupancy_status': str(vehicle.occupancy_status)\n",
    "            })\n",
    "  return matching_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance_to_stop(group):\n",
    "    group['distance_to_stop'] = group.apply(\n",
    "        lambda row: geodesic(\n",
    "            (row['vehicle_latitude'], row['vehicle_longitude']),\n",
    "            (row['stop_lat_trip'], row['stop_lon_trip'])\n",
    "        ).meters,\n",
    "        axis=1\n",
    "    )\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kd_tree_range_query(df, threshold_degrees):\n",
    "    coords = df[['vehicle_latitude','vehicle_longitude']].to_numpy()\n",
    "    tree = KDTree(coords)\n",
    "    return tree.query_pairs(threshold_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(row):\n",
    "    if pd.isna(row['previous_stop_lat']) or pd.isna(row['previous_stop_lon']):\n",
    "        return 0\n",
    "    coord1 = (row['stop_lat'], row['stop_lon'])\n",
    "    coord2 = (row['previous_stop_lat'], row['previous_stop_lon'])\n",
    "    return geodesic(coord1, coord2).meters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static GTFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_out()\n",
    "\n",
    "# Read txt files\n",
    "routes = pd.read_csv(Path(input, data_set, 'routes.txt').resolve(), sep=',')\n",
    "trips = pd.read_csv(Path(input, data_set, 'trips.txt'), sep=',')\n",
    "stop_times = pd.read_csv(Path(input, data_set, 'stop_times.txt'), sep=',')\n",
    "stops = pd.read_csv(Path(input, data_set, 'stops.txt'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get route_id given the route_short_name (eg 510) They are almost always the same...\n",
    "route_id = routes.loc[routes['route_short_name'] == int(target_route), 'route_id'].iloc[0]\n",
    "\n",
    "# Get all trip_ids with route_id = target route\n",
    "route_trips = trips.loc[trips['route_id'] == route_id][['trip_id', 'direction_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with stop_times to get arrival/departure times\n",
    "route_stop_times = stop_times.merge(route_trips, on='trip_id')[['trip_id', 'direction_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence']]\n",
    "\n",
    "# Merge with stops to get stop locations\n",
    "route_stop_info = route_stop_times.merge(stops[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']], on='stop_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply time normalization (for >24 hours) and convert to datetime format\n",
    "route_stop_info[\"arrival_time\"] = route_stop_info[\"arrival_time\"].apply(normalize_time)\n",
    "route_stop_info[\"arrival_time\"] = pd.to_datetime(route_stop_info[\"arrival_time\"], format=\"%H:%M:%S\").dt.time\n",
    "\n",
    "# Combine arrival_time with today's date to create datetime objects\n",
    "today = pd.Timestamp.now().normalize()  # Get today's date at 00:00:00\n",
    "route_stop_info[\"arrival_datetime\"] = route_stop_info[\"arrival_time\"].apply(\n",
    "    lambda t: datetime.combine(today, t)\n",
    ")\n",
    "\n",
    "# Filter rows to 1 minute in future\n",
    "current_time = pd.Timestamp.now()\n",
    "time_diff = (route_stop_info[\"arrival_datetime\"] - current_time)\n",
    "route_stop_info = route_stop_info[(time_diff <= pd.Timedelta(minutes=1)) & (time_diff > pd.Timedelta(0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display arrival/departure times and lat/lon coordinates for each stop \n",
    "static_result = route_stop_info[['trip_id', 'stop_id', 'direction_id', 'stop_name', 'arrival_time', 'departure_time', 'stop_lat', 'stop_lon', 'stop_sequence']]\n",
    "static_result = static_result.sort_values(by='direction_id')\n",
    "\n",
    "# Count unique trip_ids just out of curiosity\n",
    "unique_trip_count = static_result[\"trip_id\"].nunique()\n",
    "# print(unique_trip_count)\n",
    "\n",
    "# Save to csv\n",
    "static_result.reset_index(drop = True, inplace = True)\n",
    "static_result.to_csv(Path(output, str(target_route) + \"-static.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realtime GTFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse realtime protobuf feed\n",
    "feed = gtfs_realtime_pb2.FeedMessage()\n",
    "response = requests.get('https://bustime.ttc.ca/gtfsrt/vehicles')\n",
    "feed.ParseFromString(response.content)\n",
    "current_time = pd.Timestamp.now().time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all vehicles currently on this route\n",
    "vehicles_on_route = parse_feed_and_filter_by_route(feed, target_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from dictionary keys to desired column names\n",
    "key_to_column = {\n",
    "    'id': 'vehicle_id',\n",
    "    'trip_id': 'trip_id',\n",
    "    'route_id': 'route_id',\n",
    "    'latitude': 'vehicle_latitude',\n",
    "    'longitude': 'vehicle_longitude',\n",
    "    'occupancy_status': 'occupancy_status'\n",
    "}\n",
    "\n",
    "# Create the DataFrame, remove duplicate vehicles\n",
    "realtime_vehicles = pd.DataFrame(\n",
    "    [{new_key: d.get(old_key) for old_key, new_key in key_to_column.items()} for d in vehicles_on_route])\n",
    "realtime_vehicles.drop_duplicates()\n",
    "\n",
    "# Add current timestampt to df and convert trip_id from obj to int\n",
    "realtime_vehicles['now'] = current_time\n",
    "realtime_vehicles['trip_id'] = realtime_vehicles['trip_id'].astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with trips to get direction_id\n",
    "realtime_result = trips.merge(realtime_vehicles, on='trip_id', how='inner')\n",
    "\n",
    "# Count unique trip_ids\n",
    "unique_trip_count = realtime_result[\"trip_id\"].nunique()\n",
    "# print(unique_trip_count)\n",
    "\n",
    "# Save to csv\n",
    "realtime_result.to_csv(Path(output, str(target_route) + \"-rt.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Time Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge rt info with static info\n",
    "rt_static_merged_trips = realtime_result.merge(static_result, on='trip_id', how='outer')\n",
    "rt_static_merged_trips = rt_static_merged_trips.dropna()\n",
    "# rt_static_merged_trips = rt_static_merged_trips.drop(['Unnamed: 0_x', 'Unnamed: 0_y', 'route_id'], axis=1).dropna()\n",
    "rt_static_merged_trips.reset_index(drop = True, inplace = True)\n",
    "rt_static_merged_trips.to_csv(Path(output, str(target_route) + '-rt-static.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stop_times with stops\n",
    "stop_info = stop_times.merge(stops, on=\"stop_id\")\n",
    "stop_info = stop_info[[\"trip_id\", \"arrival_time\", \"departure_time\", \"stop_id\", \"stop_sequence\", \"stop_lat\", \"stop_lon\", \"stop_name\"]]\n",
    "\n",
    "# Merge stop_info and rt_static_trips on trip_id\n",
    "merged = stop_info.merge(rt_static_merged_trips, on=\"trip_id\", suffixes=(\"_trip\", \"_rt\"))\n",
    "merged = merged[[\"trip_id\", \"now\", \"arrival_time_trip\", \"departure_time_trip\", \"stop_sequence_trip\", \"stop_sequence_rt\",\n",
    "                \"stop_lat_trip\", \"stop_lon_trip\", \"stop_name_trip\", \"vehicle_latitude\", \"vehicle_longitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where rt stop_sequence is within n stops of the intended stop_sequence\n",
    "filtered = merged[\n",
    "    ((merged[\"stop_sequence_rt\"] - merged[\"stop_sequence_trip\"]).abs() <= n_stops)\n",
    "]\n",
    "filtered_data = filtered[[\"trip_id\", \"stop_sequence_trip\", \"now\", \"arrival_time_trip\", \"departure_time_trip\", \"stop_name_trip\", \"stop_lat_trip\", \"stop_lon_trip\", \"vehicle_latitude\", \"vehicle_longitude\"]]\n",
    "# filtered_data.to_csv(Path(output, 'filtered_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance to each stop\n",
    "calculated_distance = filtered_data.groupby(\"trip_id\").apply(find_distance_to_stop, include_groups=False).reset_index(drop=False)\n",
    "calculated_distance = calculated_distance.drop(columns=['level_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which stop is the closest (by stop_sequence)\n",
    "calculated_distance['closest_stop_sequence'] = (\n",
    "    calculated_distance.groupby('trip_id')['distance_to_stop']\n",
    "    .transform(lambda x: calculated_distance.loc[x.idxmin(), 'stop_sequence_trip'])\n",
    ")\n",
    "calculated_distance.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Save the realtime stop name of only the closest stop\n",
    "calculated_distance['stop_name_trip'] = (\n",
    "    calculated_distance.groupby('trip_id')\n",
    "        .apply(lambda group: group.loc[group['stop_sequence_trip'] == group['closest_stop_sequence'], 'stop_name_trip'], include_groups=False)\n",
    "        .reset_index(level=0, drop=True)\n",
    ")\n",
    "# calculated_distance.to_csv(Path(output, 'calculated_distance.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_static_merged_trips_concise = rt_static_merged_trips[['trip_id', 'stop_sequence', 'stop_name']]\n",
    "calculated_distance_concise = calculated_distance[['trip_id', 'closest_stop_sequence', 'stop_name_trip']].dropna()\n",
    "comparison = (calculated_distance_concise.merge(rt_static_merged_trips_concise, on='trip_id', how='outer'))[['trip_id', 'stop_sequence', 'stop_name', 'closest_stop_sequence', 'stop_name_trip']]\n",
    "# comparison.to_csv(Path(output, 'comparison.csv'))\n",
    "\n",
    "# Evaluate whether bus is on/ahead/behind schedule\n",
    "otp_result = comparison.drop_duplicates()\n",
    "temp = otp_result.copy()\n",
    "temp.loc[:, 'status'] = otp_result.apply(\n",
    "    lambda row: \n",
    "        'on' if row['closest_stop_sequence'] == row['stop_sequence'] \n",
    "        else\n",
    "        'ahead' if row['closest_stop_sequence'] > row['stop_sequence'] \n",
    "        else\n",
    "        'behind',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "temp = temp.rename({'closest_stop_sequence': 'realtime_stop_sequence',\n",
    "                    'stop_name_trip': 'realtime_stop_name', \n",
    "                    'stop_sequence': 'static_stop_sequence', \n",
    "                    'stop_name': 'static_stop_name'}, axis=1)\n",
    "temp['static_stop_sequence'] = temp['static_stop_sequence'].astype(int)\n",
    "otp_result = temp.copy()\n",
    "\n",
    "# Save to csv\n",
    "otp_result.reset_index(drop = True, inplace = True)\n",
    "otp_result.to_csv(Path(output, 'otp-analysis-result.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bus Bunching Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtime_result.groupby('direction_id').get_group(0)[['vehicle_latitude','vehicle_longitude']].to_csv(Path(output, 'direction_0_coords.csv'), index=False)\n",
    "realtime_result.groupby('direction_id').get_group(1)[['vehicle_latitude','vehicle_longitude']].to_csv(Path(output, 'direction_1_coords.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stop_sequence and stop_id of all stops on this route using the index 0 trip_id from route_trips\n",
    "stop_instances = stop_times[stop_times['trip_id'] == route_trips.iloc[0]['trip_id']][['stop_id', 'stop_sequence']]\n",
    "\n",
    "# Merge stop_instances with stops on stop_id to get stop coordinates\n",
    "target_stop_info = stop_instances.merge(stops[['stop_id', 'stop_lat', 'stop_lon']], on='stop_id')[['stop_sequence', 'stop_lat', 'stop_lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift the DataFrame to get the previous row\n",
    "target_stop_info['previous_stop_lat'] = target_stop_info['stop_lat'].shift(1)\n",
    "target_stop_info['previous_stop_lon'] = target_stop_info['stop_lon'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the distance function\n",
    "target_stop_info['distance_to_previous_stop'] = target_stop_info.apply(calculate_distance, axis=1)\n",
    "# target_stop_info.to_csv(Path(output, 'target_stop_info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average inter stop distances for route\n",
    "threshold_km = target_stop_info['distance_to_previous_stop'].mean()/1000\n",
    "threshold_degrees = threshold_km / 111  # Convert km to degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 2), (5, 8), (9, 12), (8, 9), (3, 6), (8, 12), (5, 9)}\n",
      "{(5, 7), (14, 19), (0, 2), (5, 16), (9, 14), (0, 5), (2, 5), (2, 11), (0, 11), (7, 16), (4, 5), (4, 11), (0, 1), (0, 7), (2, 4), (1, 2), (0, 4), (9, 19), (8, 17), (11, 16), (1, 11), (0, 16), (2, 7), (1, 5), (2, 16), (6, 13), (4, 7), (4, 16), (5, 11), (1, 4), (1, 7), (7, 11)}\n",
      "39 bunched bus pairs out of 34 total buses running on route 510\n"
     ]
    }
   ],
   "source": [
    "# Create kd tree and make range query for bunched buses for each direction\n",
    "# print(rt_trips)\n",
    "result = realtime_result.groupby('direction_id').apply(lambda group: kd_tree_range_query(group, threshold_degrees), include_groups=False)\n",
    "print(result.loc[0])\n",
    "print(result.loc[1])\n",
    "print(\"%s bunched bus pairs out of %s total buses running on route %s\" %(len(result.loc[0]) + len(result.loc[1]), len(realtime_result), target_route))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vehicle Occupancy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current expected occupancy is 1 while the actual occupancy on route 510 is 0.5\n"
     ]
    }
   ],
   "source": [
    "# Analyze vehicle occupancy by marking current occupancy status to expected occupancy\n",
    "df_now = (pd.to_datetime(realtime_result['now'], format=\"%H:%M:%S.%f\").dt.time).iloc[0]\n",
    "\n",
    "# Combine with today's date to create a datetime object\n",
    "combined_datetime = datetime.combine(date.today(), df_now)\n",
    "resulting_timestamp = pd.Timestamp(combined_datetime)\n",
    "\n",
    "timestamp = resulting_timestamp.time()\n",
    "realtime_result['occupancy_status'] = realtime_result['occupancy_status'].astype(str).astype(int)\n",
    "average_vehicle_occupancy = realtime_result['occupancy_status'].mean()\n",
    "\n",
    "time_7am = time(7, 0)\n",
    "time_10am = time(10, 0)\n",
    "time_4pm = time(16, 0)\n",
    "time_7pm = time(19, 0)\n",
    "\n",
    "if(resulting_timestamp.weekday() < 5):\n",
    "    if((timestamp > time_7am and timestamp  < time_10am) or (timestamp > time_4pm and timestamp < time_7pm)):\n",
    "        current_time_bucket = WEEKDAY_PEAK\n",
    "    elif(timestamp > time_10am and timestamp < time_4pm):\n",
    "        current_time_bucket = WEEKDAY_SHOULDER\n",
    "    else:\n",
    "        current_time_bucket = WEEKDAY_OFF_PEAK\n",
    "else:\n",
    "    if(timestamp > time_10am and timestamp < time_4pm):\n",
    "        current_time_bucket = WEEKEND_PEAK\n",
    "    else:\n",
    "        current_time_bucket = WEEKEND_OFF_PEAK\n",
    "\n",
    "print('The current expected occupancy is %s while the actual occupancy on route %s is %s' %(current_time_bucket, target_route, average_vehicle_occupancy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Service Guarantee Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_static_trips = len(static_result)\n",
    "# print(num_static_trips)\n",
    "num_realtime_trips = len(realtime_result)\n",
    "# print(num_realtime_trips)\n",
    "num_static_realtime_trips = len(rt_static_merged_trips)\n",
    "# print(num_static_realtime_trips)\n",
    "\n",
    "print('Percentage of static trips represented by scheduled realtime trips is {:.2f}%'.format(num_static_realtime_trips / num_static_trips * 100))\n",
    "print('Additional (unscheduled) realtime trips account for {:.2f}% of the realtime trips'.format((num_realtime_trips - num_static_realtime_trips) / num_realtime_trips * 100))\n",
    "print('Percentage of static trips represented by both scheduled and unscheduled realtime trips is {:.2f}%'.format(num_realtime_trips / num_static_trips * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
